setwd("D:/Data Science Project/Amazon echo Dot 2 reviews prediction")
# Natural Language Processing
#setwd('D:/Data Science Project/Amazon echo Dot 2 reviews prediction')
# Importing the dataset
dataset=read.csv("Amazon Echo 2 Reviews.csv",stringsAsFactors = FALSE)
dataset=dataset[c('Title','Review.Text','Rating')]
dataset$Rating=ifelse(dataset$Rating>3,1,0)
dataset$Rating=as.integer(dataset$Rating)
sapply(dataset,typeof)
apply(dataset,2,function(col)sum(is.na(col))/length(col))
summary(dataset)
# Cleaning the texts
#install.packages('NLP')
library(NLP)
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset[c(-3)]))
corpus=tm_map(corpus,content_transformer(tolower))
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords())
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
# Creating the Bag of words Model
dtn=DocumentTermMatrix(corpus)
dtn=removeSparseTerms(dtn,0.999)
dataset=as.data.frame(as.matrix(dtn))
dataset$Rating=factor(dataset$Rating,levels = c(0,1))
# Splitting the dataset into the training set and the test set
library(caTools)
set.seed(123)
split=sample.split(dataset$Rating,SplitRatio = 0.80)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
View(training_set)
# Natural Language Processing
#setwd('D:/Data Science Project/Amazon echo Dot 2 reviews prediction')
# Importing the dataset
dataset=read.csv("Amazon Echo 2 Reviews.csv",stringsAsFactors = FALSE)
dataset=dataset[c('Title','Review.Text','Rating')]
dataset$Rating=ifelse(dataset$Rating>3,1,0)
dataset$Rating=as.integer(dataset$Rating)
sapply(dataset,typeof)
apply(dataset,2,function(col)sum(is.na(col))/length(col))
summary(dataset)
# Cleaning the texts
#install.packages('NLP')
library(NLP)
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset[c(-3)]))
corpus=tm_map(corpus,content_transformer(tolower))
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords())
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
# Creating the Bag of words Model
dtn=DocumentTermMatrix(corpus)
dtn=removeSparseTerms(dtn,0.999)
dataset=as.data.frame(as.matrix(dtn))
# Encoding the Categorical Data
dataset$Rating=factor(dataset$Rating,levels = c(0,1))
# Splitting the dataset into the training set and the test set
library(caTools)
set.seed(123)
split=sample.split(dataset$Rating,SplitRatio = 0.80)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
# Fitting the Logistic Regression to the Training set
classifier=glm(Rating ~.,family=binomial,data=training_set)
y_pred=predict(classifier,newdata=test_set[-3])
classifier=glm(Rating ~.,family=binomial,data=training_set)
classifier=glm(dataset$Rating ~.,family=binomial,data=training_set)
classifier=glm(formula=Rating ~.,family=binomial,data=training_set)
View(training_set)
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3:5]
setwd("D:/Data Science Project/Amazon echo Dot 2 reviews prediction")
dataset=read.csv('Social_Network_Ads.csv')
dataset=dataset[3:5]
library(caTools)
set.seed(123)
split=sample.split(dataset$Purchased,SplitRatio = 0.75)
training_set=subset(dataset,split==TRUE)
test_set=subset(dataset,split==FALSE)
dataset=read.csv("Amazon Echo 2 Reviews.csv",stringsAsFactors = FALSE)
dataset=dataset[c('Title','Review.Text','Rating')]
dataset$Rating=ifelse(dataset$Rating>3,1,0)
dataset$Rating=as.integer(dataset$Rating)
sapply(dataset,typeof)
apply(dataset,2,function(col)sum(is.na(col))/length(col))
summary(dataset)
library(NLP)
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset[c(-3)]))
corpus=tm_map(corpus,content_transformer(tolower))
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords())
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
dtn=DocumentTermMatrix(corpus)
dtn=removeSparseTerms(dtn,0.999)
dataset=as.data.frame(as.matrix(dtn))
typeof(dataset)
typeof(dtn)
type(dtn)
# Natural Language Processing
#setwd('D:/Data Science Project/Amazon echo Dot 2 reviews prediction')
# Importing the dataset
dataset=read.csv("Amazon Echo 2 Reviews.csv",stringsAsFactors = FALSE)
dataset=dataset[c('Title','Review.Text','Rating')]
dataset$Rating=ifelse(dataset$Rating>3,1,0)
dataset$Rating=as.integer(dataset$Rating)
sapply(dataset,typeof)
apply(dataset,2,function(col)sum(is.na(col))/length(col))
summary(dataset)
# Cleaning the texts
#install.packages('NLP')
library(NLP)
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset[c(-3)]))
corpus=tm_map(corpus,content_transformer(tolower))
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords())
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
# Creating the Bag of words Model
dtn=DocumentTermMatrix(corpus)
dtn=removeSparseTerms(dtn,0.999)
typeof(dtn)
dataset=as.data.frame(as.matrix(dtn))
typeof(dataset)
class(dataset)
typeof(dataset)
dataset=as.data.frame(as.matrix(dtn))
dataset$Rating=factor(dataset$Rating,levels = c(0,1))
View(dataset)
# Natural Language Processing
#setwd('D:/Data Science Project/Amazon echo Dot 2 reviews prediction')
# Importing the dataset
dataset=read.csv("Amazon Echo 2 Reviews.csv",stringsAsFactors = FALSE)
dtn=DocumentTermMatrix(corpus)
dtn=removeSparseTerms(dtn,0.999)
dataset=read.csv("Amazon Echo 2 Reviews.csv",stringsAsFactors = FALSE)
dataset=dataset[c('Title','Review.Text','Rating')]
dataset$Rating=ifelse(dataset$Rating>3,1,0)
dataset$Rating=as.integer(dataset$Rating)
sapply(dataset,typeof)
apply(dataset,2,function(col)sum(is.na(col))/length(col))
summary(dataset)
# Cleaning the texts
#install.packages('NLP')
library(NLP)
library(tm)
library(SnowballC)
corpus=VCorpus(VectorSource(dataset[c(-3)]))
corpus=tm_map(corpus,content_transformer(tolower))
corpus=tm_map(corpus,removeNumbers)
corpus=tm_map(corpus,removePunctuation)
corpus=tm_map(corpus,removeWords,stopwords())
corpus=tm_map(corpus,stemDocument)
corpus=tm_map(corpus,stripWhitespace)
# Creating the Bag of words Model
dtn=DocumentTermMatrix(corpus)
dtn=removeSparseTerms(dtn,0.999)
